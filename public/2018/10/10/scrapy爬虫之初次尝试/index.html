<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>scrapy爬虫之初次尝试 | MagicYou</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.3.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">scrapy爬虫之初次尝试</h1><a id="logo" href="/.">MagicYou</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/tags/"><i class="fa fa-tag"> 标签</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">scrapy爬虫之初次尝试</h1><div class="post-meta">Oct 10, 2018<span> | </span><span class="category"><a href="/categories/Python/">Python</a></span></div><div class="post-content"><p>本文主要记录scrapy安装、配置，到第一个爬虫实例实现的过程。</p>
<a id="more"></a>
<h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><h4 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h4><ul>
<li>环境：macOS</li>
<li>python版本：python 3.7</li>
<li>Scrapy版本：1.5.1</li>
</ul>
<h4 id="安装scrapy"><a href="#安装scrapy" class="headerlink" title="安装scrapy"></a>安装scrapy</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install scrapy</span><br></pre></td></tr></table></figure>
<h4 id="创建Scrapy项目"><a href="#创建Scrapy项目" class="headerlink" title="创建Scrapy项目"></a>创建Scrapy项目</h4><p>创建python目录，切换到python目录,创建爬虫项目<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">magicyou@magicYoudeMacBook-Pro ~$ mkdir ~/python</span><br><span class="line">magicyou@magicYoudeMacBook-Pro ~$ cd ~/python</span><br><span class="line">magicyou@magicYoudeMacBook-Pro python$ scrapy startproject articleSpider</span><br><span class="line">New Scrapy project &apos;articleSpider&apos;, using template directory &apos;/usr/local/lib/python3.7/site-packages/scrapy/templates/project&apos;, created in:</span><br><span class="line">    /Users/magicyou/Desktop/python/articleSpider</span><br><span class="line"></span><br><span class="line">You can start your first spider with:</span><br><span class="line">    cd articleSpider</span><br><span class="line">    scrapy genspider example example.com</span><br></pre></td></tr></table></figure></p>
<p>创建一个Spider爬虫程序。本文进行抓取的模板网站 ‘blog.jobbole.com’，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">magicyou@magicYoudeMacBook-Pro python$ cd articleSpider</span><br><span class="line">magicyou@magicYoudeMacBook-Pro articleSpider$ scrapy genspider jobbole blog.jobbole.com</span><br><span class="line">Created spider &apos;jobbole&apos; using template &apos;basic&apos; in module:</span><br><span class="line">  articleSpider.spiders.jobbole</span><br></pre></td></tr></table></figure>
<h4 id="创建一个mysql表，用来存储文章信息"><a href="#创建一个mysql表，用来存储文章信息" class="headerlink" title="创建一个mysql表，用来存储文章信息"></a>创建一个mysql表，用来存储文章信息</h4><p>直接上sql<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> <span class="string">`article`</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`article`</span> (</span><br><span class="line">  <span class="string">`url_object_id`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">COLLATE</span> utf8_unicode_ci <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'url的md5'</span>,</span><br><span class="line">  <span class="string">`url`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">COLLATE</span> utf8_unicode_ci <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'url'</span>,</span><br><span class="line">  <span class="string">`title`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">COLLATE</span> utf8_unicode_ci <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'文章名字'</span>,</span><br><span class="line">  <span class="string">`create_date`</span> <span class="built_in">date</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'创建日期'</span>,</span><br><span class="line">  <span class="string">`front_image_url`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">COLLATE</span> utf8_unicode_ci <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'封面路原始url'</span>,</span><br><span class="line">  <span class="string">`front_image_path`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">COLLATE</span> utf8_unicode_ci <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'封面图本地路径'</span>,</span><br><span class="line">  <span class="string">`comment_nums`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'评论数'</span>,</span><br><span class="line">  <span class="string">`fav_nums`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'点赞数'</span>,</span><br><span class="line">  <span class="string">`praise_nums`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`content`</span> longtext <span class="keyword">COLLATE</span> utf8_unicode_ci <span class="keyword">COMMENT</span> <span class="string">'文章内容'</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`url_object_id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8 <span class="keyword">COLLATE</span>=utf8_unicode_ci;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> FOREIGN_KEY_CHECKS = <span class="number">1</span>;</span><br></pre></td></tr></table></figure></p>
<p>至此准备工作基本完成<br>此时的目录结构应该是如下展示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">|-- articleSpider</span><br><span class="line">    |--- articleSpider</span><br><span class="line">        |-- spiders    # Spiders类</span><br><span class="line">        	|-- jobbole.py</span><br><span class="line">        	|-- __init__.py</span><br><span class="line">        	|-- __pycache__</span><br><span class="line">            	|-- __init__.cpython-37.pyc</span><br><span class="line">        |-- __pycache__</span><br><span class="line">            |-- settings.cpython-37.pyc</span><br><span class="line">            |-- __init__.cpython-37.pyc</span><br><span class="line">        |-- middlewares.</span><br><span class="line">        |-- pipelines.py</span><br><span class="line">        |-- items.py</span><br><span class="line">        |-- settings.py</span><br><span class="line">        |-- __init__.py</span><br><span class="line">    |-- scrapy.cfg</span><br></pre></td></tr></table></figure></p>
<h3 id="简单的了解"><a href="#简单的了解" class="headerlink" title="简单的了解"></a>简单的了解</h3><h4 id="Spiders"><a href="#Spiders" class="headerlink" title="Spiders"></a>Spiders</h4><p>Spider类定义了如何爬取某个(或某些)网站。包括了爬取的动作(例如:是否跟进链接)以及如何从网页的内容中提取结构化数据(爬取item)。 换句话说，Spider就是您定义爬取的动作及分析某个网页(或者是有些网页)的地方。</p>
<p>对spider来说，爬取的循环类似下文:</p>
<ul>
<li><p>以初始的URL初始化Request，并设置回调函数。 当该request下载完毕并返回时，将生成response，并作为参数传给该回调函数。</p>
<p>spider中初始的request是通过调用 start_requests() 来获取的。 start_requests() 读取 start_urls 中的URL， 并以 parse 为回调函数生成 Request 。</p>
</li>
<li><p>在回调函数内分析返回的(网页)内容，返回 Item 对象或者 Request 或者一个包括二者的可迭代容器。 返回的Request对象之后会经过Scrapy处理，下载相应的内容，并调用设置的callback函数(函数可相同)。</p>
</li>
<li><p>在回调函数内，您可以使用 选择器(Selectors) (您也可以使用BeautifulSoup, lxml 或者您想用的任何解析器) 来分析网页内容，并根据分析的数据生成item。</p>
</li>
<li><p>最后，由spider返回的item将被存到数据库(由某些 Item Pipeline 处理)或使用 Feed exports </p>
</li>
</ul>
<h4 id="Items"><a href="#Items" class="headerlink" title="Items"></a>Items</h4><p>爬取的主要目标就是从非结构性的数据源提取结构性数据，例如网页。 Scrapy提供 Item 类来满足这样的需求。<br>Item 对象是种简单的容器，保存了爬取到得数据。 其提供了 类似于词典(dictionary-like) 的API以及用于声明可用字段的简单语法。</p>
<h4 id="Item-Pipeline"><a href="#Item-Pipeline" class="headerlink" title="Item Pipeline"></a>Item Pipeline</h4><p>当Item在Spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item的处理。</p>
<p>每个item pipeline组件(有时称之为“Item Pipeline”)是实现了简单方法的Python类。他们接收到Item并通过它执行一些行为，同时也决定此Item是否继续通过pipeline，或是被丢弃而不再进行处理。</p>
<p>以下是item pipeline的一些典型应用：</p>
<ul>
<li>清理HTML数据</li>
<li>验证爬取的数据(检查item包含某些字段)</li>
<li>查重(并丢弃)</li>
<li>将爬取结果保存到数据库中</li>
</ul>
<h3 id="爬虫逻辑编写"><a href="#爬虫逻辑编写" class="headerlink" title="爬虫逻辑编写"></a>爬虫逻辑编写</h3><p>入口文件 main.py<br>编辑器是PyCharm，为了调试方便，添加main.py作为程序的入口，切换在articleSpider操作(当前路径 ~/python/articleSpider/articleSpider)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python3</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">__author__ = <span class="string">'magicYou'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.cmdline <span class="keyword">import</span> execute</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">print(os.path.dirname(os.path.abspath(__file__)))</span><br><span class="line">sys.path.append(os.path.dirname(os.path.abspath(__file__)))</span><br><span class="line">execute([<span class="string">"scrapy"</span>, <span class="string">"crawl"</span>, <span class="string">"jobbole"</span>])</span><br></pre></td></tr></table></figure>
<p>Spider爬虫使用parse(self,response)方法来解析所下载的页面。此方法返回一个包含新的URL资源网址的迭代对象，这些新的URL网址将被添加到下载队列中以供将来进行爬取数据和解析。<br>spider主要代码（python/articleSpider/articleSpider/jobbole.py）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> parse</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> articleSpider.items <span class="keyword">import</span> JobboleArticlespiderItem</span><br><span class="line"><span class="keyword">from</span> .utils.common <span class="keyword">import</span> get_md5</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobboleSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'jobbole'</span></span><br><span class="line">    allowed_domains = [<span class="string">'blog.jobbole.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://blog.jobbole.com/all-posts/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        1.获取文章列表中的文章url并交给scrapy下载并进行解析</span></span><br><span class="line"><span class="string">        2.获取下一页的url并交给scary进行下载，下载完成后交给parse</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        post_nodes = response.css(<span class="string">"#archive .floated-thumb .post-thumb a"</span>)</span><br><span class="line">        <span class="keyword">for</span> post_node <span class="keyword">in</span> post_nodes:</span><br><span class="line">            image_url = post_node.css(<span class="string">"img::attr(src)"</span>).extract_first(<span class="string">""</span>)</span><br><span class="line">            post_url = post_node.css(<span class="string">"::attr(href)"</span>).extract_first()</span><br><span class="line">            <span class="keyword">yield</span> Request(url=parse.urljoin(response.url, post_url), meta=&#123;<span class="string">"front_image_url"</span>:image_url&#125;, callback=self.parse_detail)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取下一页并交给scrapy进行下载</span></span><br><span class="line">        next_urls = response.css(<span class="string">".next.page-numbers::attr(href)"</span>).extract_first(<span class="string">""</span>)</span><br><span class="line">        <span class="keyword">if</span> next_urls:</span><br><span class="line">            <span class="keyword">yield</span> Request(url=parse.urljoin(response.url, next_urls), callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_detail</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        详情页信息提取</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        article = JobboleArticlespiderItem()</span><br><span class="line">        url = response.url</span><br><span class="line">        title = response.xpath(<span class="string">"//div[@class='entry-header']/h1/text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        create_date = response.xpath(<span class="string">"//div[@class='entry-meta']/p[@class='entry-meta-hide-on-mobile']/text()"</span>).extract()[<span class="number">0</span>].strip()</span><br><span class="line">        create_date = datetime.strptime(create_date.split()[<span class="number">0</span>], <span class="string">"%Y/%m/%d"</span>)</span><br><span class="line">        praise_nums = response.xpath(<span class="string">"//div[@class='post-adds']/span[contains(@class, 'vote-post-up')]/h10/text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        fav_nums = response.xpath(<span class="string">"//div[@class='post-adds']/span[contains(@class, 'bookmark-btn')]/text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        fav_nums = fav_nums.replace(<span class="string">'收藏'</span>, <span class="string">''</span>) <span class="keyword">if</span> fav_nums.replace(<span class="string">'收藏'</span>, <span class="string">''</span>).strip() <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        comment_nums = response.xpath(<span class="string">"//div[@class='post-adds']/a[@href='#article-comment']/span/text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        comment_nums = comment_nums.replace(<span class="string">'评论'</span>, <span class="string">''</span>) <span class="keyword">if</span> comment_nums.replace(<span class="string">'评论'</span>, <span class="string">''</span>).strip() <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        content = response.xpath(<span class="string">"//div[@class='entry']"</span>).extract()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取图片</span></span><br><span class="line">        front_image_url = response.meta.get(<span class="string">"front_image_url"</span>, <span class="string">""</span>)</span><br><span class="line">        article_item = &#123;&#125;</span><br><span class="line">        article_item[<span class="string">"url"</span>] = url</span><br><span class="line">        article_item[<span class="string">"url_object_id"</span>] = get_md5(url)</span><br><span class="line">        article_item[<span class="string">"title"</span>] = title</span><br><span class="line">        article_item[<span class="string">"create_date"</span>] = create_date</span><br><span class="line">        article_item[<span class="string">"praise_nums"</span>] = int(praise_nums)</span><br><span class="line">        article_item[<span class="string">"fav_nums"</span>] = int(fav_nums)</span><br><span class="line">        article_item[<span class="string">"comment_nums"</span>] = int(comment_nums)</span><br><span class="line">        article_item[<span class="string">"content"</span>] = content</span><br><span class="line">        article_item[<span class="string">"front_image_url"</span>] = [front_image_url]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">yield</span> article_item</span><br></pre></td></tr></table></figure></p>
<p>过程简单描述</p>
<ol>
<li>parse函数从start_urls为起始页，获取列表里的文章url，和文章的封面图url；</li>
<li>讲步骤1中的获取的url交给parse_detail，进行详情处理，处理结果交付给item；</li>
<li>获取下一页的url，作为参数再次交给parse函数，直到没有下一页为止。</li>
</ol>
<p>Item使用简单的class定义语法以及 Field 对象来声明<br>items主要代码（python/articleSpider/items.py）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line">class ArticleItem(scrapy.Item):</span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    url = scrapy.Field()</span><br><span class="line">    url_object_id = scrapy.Field()</span><br><span class="line">    crate_date = scrapy.Field()</span><br><span class="line">    praise_nums = scrapy.Field()</span><br><span class="line">    fav_nums = scrapy.Field()</span><br><span class="line">    comment_nums = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br><span class="line">    front_image_url = scrapy.Field()</span><br></pre></td></tr></table></figure></p>
<p>pipeline中接收item传过来的数据，并且存入数据库</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> twisted.enterprise <span class="keyword">import</span> adbapi</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ArticleImagePipeline</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    存储图片，并返回存储的路径</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span><span class="params">(self, results, item, info)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> ok, value <span class="keyword">in</span> results:</span><br><span class="line">            image_file_path = value[<span class="string">'path'</span>]</span><br><span class="line">        <span class="comment"># 给item添加图片本地存储路径</span></span><br><span class="line">        item[<span class="string">"front_image_path"</span>] = image_file_path</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MysqlPipeline</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    同步存储mysql，比较慢</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, params)</span>:</span></span><br><span class="line">        self.conn = pymysql.connect( host = params[<span class="string">'host'</span>],</span><br><span class="line">                                     user = params[<span class="string">'user'</span>],</span><br><span class="line">                                     password = params[<span class="string">'password'</span>],</span><br><span class="line">                                     db = params[<span class="string">'db'</span>],</span><br><span class="line">                                     charset = params[<span class="string">'charset'</span>],</span><br><span class="line">                                     cursorclass = pymysql.cursors.DictCursor)</span><br><span class="line">        self.cursor = self.conn.cursor()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        获取settings文件中的配置</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        params = crawler.settings.get(<span class="string">'MYSQL'</span>)</span><br><span class="line">        <span class="keyword">return</span> cls(params)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        insert_sql = <span class="string">'''</span></span><br><span class="line"><span class="string">            insert into article </span></span><br><span class="line"><span class="string">               (title, create_date, url, url_object_id, front_image_url, front_image_path, comment_nums, fav_nums, praise_nums, content)</span></span><br><span class="line"><span class="string">            values </span></span><br><span class="line"><span class="string">                ('%s', '%s','%s', '%s', '%s', '%s', %d, %d, %d,'%s')</span></span><br><span class="line"><span class="string">        '''</span> % (item[<span class="string">'title'</span>], item[<span class="string">'create_date'</span>], item[<span class="string">'url'</span>], item[<span class="string">'url_object_id'</span>], <span class="string">','</span>.join(item[<span class="string">'front_image_url'</span>]), item[<span class="string">"front_image_path"</span>], item[<span class="string">'comment_nums'</span>], item[<span class="string">'fav_nums'</span>], item[<span class="string">'praise_nums'</span>], item[<span class="string">'content'</span>])</span><br><span class="line">        self.cursor.execute(insert_sql)</span><br><span class="line">        self.conn.commit()</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MysqlTwistedPipline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    异步存储mysql，相对较快</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, params)</span>:</span></span><br><span class="line">        <span class="comment"># 使用Twisted中的adbapi获取数据库连接池对象</span></span><br><span class="line">        self.dbpool = adbapi.ConnectionPool(<span class="string">"pymysql"</span>, **params)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls,crawler)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        获取settings文件中的配置</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        param = crawler.settings.get(<span class="string">'MYSQL'</span>)</span><br><span class="line">        params = dict(</span><br><span class="line">            host = param[<span class="string">'host'</span>],</span><br><span class="line">            user = param[<span class="string">'user'</span>],</span><br><span class="line">            password = param[<span class="string">'password'</span>],</span><br><span class="line">            db = param[<span class="string">'db'</span>],</span><br><span class="line">            charset = param[<span class="string">'charset'</span>],</span><br><span class="line">            cursorclass = pymysql.cursors.DictCursor,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> cls(params)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="comment"># 使用数据库连接池对象进行数据库操作,自动传递cursor对象到第一个参数</span></span><br><span class="line">        query = self.dbpool.runInteraction(self.do_insert, item)</span><br><span class="line">        <span class="comment"># 设置出错时的回调方法,自动传递出错消息对象failure到第一个参数</span></span><br><span class="line">        query.addErrback(self.handle_error)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handle_error</span><span class="params">(self,failure)</span>:</span></span><br><span class="line">        print(failure)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">do_insert</span><span class="params">(self, cursor, item)</span>:</span></span><br><span class="line">        insert_sql = <span class="string">'''</span></span><br><span class="line"><span class="string">            insert into article </span></span><br><span class="line"><span class="string">               (title, create_date, url, url_object_id, front_image_url, front_image_path, comment_nums, fav_nums, praise_nums, content)</span></span><br><span class="line"><span class="string">            values </span></span><br><span class="line"><span class="string">                ('%s', '%s','%s', '%s', '%s', '%s', %d, %d, %d,'%s')</span></span><br><span class="line"><span class="string">        '''</span> % (item[<span class="string">'title'</span>], item[<span class="string">'create_date'</span>], item[<span class="string">'url'</span>], item[<span class="string">'url_object_id'</span>], <span class="string">','</span>.join(item[<span class="string">'front_image_url'</span>]), item[<span class="string">"front_image_path"</span>], item[<span class="string">'comment_nums'</span>], item[<span class="string">'fav_nums'</span>], item[<span class="string">'praise_nums'</span>], item[<span class="string">'content'</span>])</span><br><span class="line">        cursor.execute(insert_sql)</span><br></pre></td></tr></table></figure>
<p>最重要的一步就是settings需要配置<br>关键的settings配置：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># Pipeline自定义一个，就要在这里添加一个，后面的数字表示执行的先后顺序，数字越大越靠后</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="comment"># 'articleSpider.pipelines.ArticlespiderPipeline': 300,</span></span><br><span class="line">    <span class="string">'scrapy.pipelines.images.ImagesPipeline'</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="string">'articleSpider.pipelines.ArticleImagePipeline'</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">'articleSpider.pipelines.MysqlPipeline'</span>: <span class="number">3</span>,</span><br><span class="line">   <span class="comment">#  'articleSpider.pipelines.MysqlTwistedPipline': 3,</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图片下载</span></span><br><span class="line"><span class="comment"># item中要下载的图片路径，数值类型必须为list</span></span><br><span class="line">IMAGES_URLS_FIELD = <span class="string">"front_image_url"</span></span><br><span class="line"><span class="comment"># 获取当前绝对路径</span></span><br><span class="line">project_dir = os.path.abspath(os.path.dirname(__file__))</span><br><span class="line"><span class="comment"># 图片存储到本地路径</span></span><br><span class="line">IMAGES_STORE = os.path.join(project_dir, <span class="string">'images'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># mysql配置参数</span></span><br><span class="line">MYSQL = &#123;<span class="string">'host'</span>:<span class="string">'localhost'</span>,<span class="string">'user'</span>:<span class="string">'root'</span>,<span class="string">'password'</span>:<span class="string">'root'</span>,<span class="string">'db'</span>:<span class="string">'jobbole'</span>,<span class="string">'charset'</span>:<span class="string">'utf8'</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ol>
<li><p>spiders目录下添加utils目录，存放常用的自定义公共方法common.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python3</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">__author__ = <span class="string">'magicYou'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_md5</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(url, str):</span><br><span class="line">        url = url.encode(<span class="string">"utf-8"</span>)</span><br><span class="line">    m = hashlib.md5()</span><br><span class="line">    m.update(url)</span><br><span class="line">    <span class="keyword">return</span> m.hexdigest()</span><br></pre></td></tr></table></figure>
</li>
<li><p>articleSpider目录下创建images，用来存储下载的图片</p>
</li>
</ol>
<h3 id="知识补充"><a href="#知识补充" class="headerlink" title="知识补充"></a>知识补充</h3><p>xpath基本语法</p>
<table>
<thead>
<tr>
<th>表达式</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>/body</td>
<td>选出当前选择器的根元素body</td>
</tr>
<tr>
<td>/body/div</td>
<td>选取当前选择器文档的根元素body的所有div子元素</td>
</tr>
<tr>
<td>/body/div[1]</td>
<td>选取body根元素下面第一个div子元素</td>
</tr>
<tr>
<td>/body/div[last()]</td>
<td>选取body根元素下面最后一个div子元素</td>
</tr>
<tr>
<td>/body/div[last()-1]</td>
<td>选取body根元素下面倒数第二个div子元素</td>
</tr>
<tr>
<td>//div</td>
<td>选取所有div子元素(不论出现在文档任何地方)</td>
</tr>
<tr>
<td>body//div</td>
<td>选取所有属于body元素的后代的div元素(不论出现在body下的任何地方)</td>
</tr>
<tr>
<td>/body/@id</td>
<td>选取当前选择器文档的根元素body的id属性</td>
</tr>
<tr>
<td>//@class</td>
<td>选取所有元素的class属性</td>
</tr>
<tr>
<td>//div[@class]</td>
<td>选取所有拥有class属性的div元素</td>
</tr>
<tr>
<td>//div[@class=’bold’]</td>
<td>选取所有class属性等于bold的div元素</td>
</tr>
<tr>
<td>//div[contains(@class,’bold’)]</td>
<td>选取所有class属性包含bold的div元素</td>
</tr>
<tr>
<td>/div/*</td>
<td>选取当前文档根元素div的所有子元素</td>
</tr>
<tr>
<td>//*</td>
<td>选取文档所有节点</td>
</tr>
<tr>
<td>//div[@*]</td>
<td>获取所有带属性的div元素</td>
</tr>
<tr>
<td>//div/a \</td>
<td>//div/p</td>
<td>选取所有div元素下面的子元素a和子元素p(并集)</td>
</tr>
<tr>
<td>//p[@id=’content’]/text()</td>
<td>选取id为content的p标签的内容(子元素的标签和内容都不会获取到)</td>
</tr>
</tbody>
</table>
<p>一个用法实例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">txt_header = response.xpath(&quot;//div[@id=&apos;wrapper_header&apos;]/h3/text()&quot;).extract()[0] # 选取wrapper_header下h3标签的内容</span><br></pre></td></tr></table></figure></p>
<p>CSS选择器</p>
<table>
<thead>
<tr>
<th>表达式</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>*</td>
<td>选择所有节点</td>
</tr>
<tr>
<td>#container</td>
<td>选择Id为container的节点</td>
</tr>
<tr>
<td>.container</td>
<td>选取所有包含container类的节点</td>
</tr>
<tr>
<td>li a</td>
<td>选取所有li下的所有后代a元素(子和孙等所有的都会选中)</td>
</tr>
<tr>
<td>ul + p</td>
<td>选取ul后面的第一个相邻兄弟p元素</td>
</tr>
<tr>
<td>div#container &gt; ul</td>
<td>选取id为container的div的所有ul子元素</td>
</tr>
<tr>
<td>ul ~ p</td>
<td>选取与ul元素后面的所有兄弟p元素</td>
</tr>
<tr>
<td>a[title]</td>
<td>选取所有有title属性的a元素</td>
</tr>
<tr>
<td>a[href=’<a href="http://taobao.com" target="_blank" rel="noopener">http://taobao.com</a>‘]</td>
<td>选取所有href属性等于<a href="http://taobao.com的a元素" target="_blank" rel="noopener">http://taobao.com的a元素</a></td>
</tr>
<tr>
<td>a[href*=’taobao’]</td>
<td>选取所有href属性包含taobao的a元素</td>
</tr>
<tr>
<td>a[href^=’http’]</td>
<td>选取所有href属性开头为http的a元素</td>
</tr>
<tr>
<td>a[href$=’.com’]</td>
<td>选取所有href属性结尾为.com的a元素</td>
</tr>
<tr>
<td>input[type=radio]:checked</td>
<td>选取选中的radio的input元素</td>
</tr>
<tr>
<td>div:not(#container)</td>
<td>选取所有id非container的div元素</td>
</tr>
<tr>
<td>li:nth-child(3)</td>
<td>选取第三个li元素</td>
</tr>
<tr>
<td>tr:nth-child(2n)</td>
<td>选取偶数位的tr元素</td>
</tr>
<tr>
<td>a::attr(href)</td>
<td>获取所有a元素的href属性值</td>
</tr>
</tbody>
</table>
<p>一个用法实例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">txt_header = response.css(&quot;#wrapper_header h3::text&quot;).extract_first()  # 选取wrapper_header下h3标签的内容</span><br></pre></td></tr></table></figure></p>
<h3 id="参考资料、视频"><a href="#参考资料、视频" class="headerlink" title="参考资料、视频"></a>参考资料、视频</h3><ol>
<li><a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/" target="_blank" rel="noopener">scrapy中文文档</a></li>
<li><a href="https://blog.csdn.net/wxystyle/article/details/81128026" target="_blank" rel="noopener">Python爬虫框架Scrapy学习笔记原创（来自CSDN）</a></li>
<li><a href="https://coding.imooc.com/class/92.html" target="_blank" rel="noopener">Python分布式爬虫打造搜索引擎（慕课视频）</a></li>
</ol>
</div><div class="tags"><a href="/tags/Python/">Python</a><a href="/tags/scrapy/">scrapy</a></div><div class="post-nav"><a class="pre" href="/2018/10/23/脚本微博登录自动发微博并返回cookie/">脚本微博登录自动发微博并返回cookie</a><a class="next" href="/2018/09/26/安装python的crypto模块/">安装python的crypto模块</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://blog.magicyou.cn"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MacOS/">MacOS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PHP/">PHP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/前端/">前端</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/vue/" style="font-size: 15px;">vue</a> <a href="/tags/JavaScript/" style="font-size: 15px;">JavaScript</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/CSS3/" style="font-size: 15px;">CSS3</a> <a href="/tags/Vue/" style="font-size: 15px;">Vue</a> <a href="/tags/PHP/" style="font-size: 15px;">PHP</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/微信小程序/" style="font-size: 15px;">微信小程序</a> <a href="/tags/Centos/" style="font-size: 15px;">Centos</a> <a href="/tags/other/" style="font-size: 15px;">other</a> <a href="/tags/jQuery/" style="font-size: 15px;">jQuery</a> <a href="/tags/scrapy/" style="font-size: 15px;">scrapy</a> <a href="/tags/HTML5/" style="font-size: 15px;">HTML5</a> <a href="/tags/Nginx/" style="font-size: 15px;">Nginx</a> <a href="/tags/Apache/" style="font-size: 15px;">Apache</a> <a href="/tags/MacOS/" style="font-size: 15px;">MacOS</a> <a href="/tags/CSS/" style="font-size: 15px;">CSS</a> <a href="/tags/HTML/" style="font-size: 15px;">HTML</a> <a href="/tags/uni-app/" style="font-size: 15px;">uni-app</a> <a href="/tags/微信小程序/" style="font-size: 15px;">微信小程序'</a> <a href="/tags/canvas/" style="font-size: 15px;">canvas</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/09/03/环形温度调节实现/">环形温度调节实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/03/ vue-组件封装中之slot插槽使用/">vue---组件封装中之slot插槽使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/03/PHP获取微信小程序码/">微信小程序---PHP获取微信小程序码</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/03/微信小程序合成海报/">微信小程序---合成海报分享到朋友圈</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/24/单点登录配置 记录/">配置webgate拦截跳转到ldap登录页实现单点登录</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/23/一次环境升级记录/">一次lnmp环境升级记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/03/yum源的代理设置及修改/">yum源的代理设置及修改</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/23/脚本微博登录自动发微博并返回cookie/">脚本微博登录自动发微博并返回cookie</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/10/scrapy爬虫之初次尝试/">scrapy爬虫之初次尝试</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/26/安装python的crypto模块/">安装python的crypto模块</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://hexo.io" title="Hexo" target="_blank">Hexo</a><ul></ul><a href="http://moxfive.xyz/" title="MOxFIVE" target="_blank">MOxFIVE</a><ul></ul><a href="https://coolshell.cn/" title="左耳朵耗子的酷壳" target="_blank">左耳朵耗子的酷壳</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">MagicYou.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.3.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.3.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.3.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.3.0"></script></div></body></html>